{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPRGX8nE0tOoPO85uKQpCwW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankitvns97/Intelligent-Face-Tracker-with-Auto--Registration-and-Visitor-Counting/blob/main/Intelligent_Face_Tracker_with_Auto_Registration_and_Visitor_Counting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########################################"
      ],
      "metadata": {
        "id": "Jxkm0vP4I1aI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics opencv-python-headless numpy facenet-pytorch deep-sort-realtime scikit-learn pandas\n",
        "!wget https://github.com/akanametov/yolov8-face/releases/download/v0.0.0/yolov8n-face.pt\n",
        "!mkdir -p logs/entries logs/exits sample_images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcWgVW_N2SFl",
        "outputId": "ee7ecadf-56c3-4e5c-8685-bde70a1fc8d2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.158)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: facenet-pytorch in /usr/local/lib/python3.11/dist-packages (2.6.0)\n",
            "Requirement already satisfied: deep-sort-realtime in /usr/local/lib/python3.11/dist-packages (1.3.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (10.2.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.17.2)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.6.15)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "--2025-06-24 07:33:25--  https://github.com/akanametov/yolov8-face/releases/download/v0.0.0/yolov8n-face.pt\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://github.com/akanametov/yolo-face/releases/download/v0.0.0/yolov8n-face.pt [following]\n",
            "--2025-06-24 07:33:26--  https://github.com/akanametov/yolo-face/releases/download/v0.0.0/yolov8n-face.pt\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/592261808/fef886fa-7bce-42bc-8056-4c0ee291b0eb?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250624%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250624T073326Z&X-Amz-Expires=1800&X-Amz-Signature=ddae4e6ba972381134875ec2085d69086b39f938bd27718c30cd44faab796354&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov8n-face.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-06-24 07:33:26--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/592261808/fef886fa-7bce-42bc-8056-4c0ee291b0eb?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250624%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250624T073326Z&X-Amz-Expires=1800&X-Amz-Signature=ddae4e6ba972381134875ec2085d69086b39f938bd27718c30cd44faab796354&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov8n-face.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6250099 (6.0M) [application/octet-stream]\n",
            "Saving to: ‘yolov8n-face.pt.1’\n",
            "\n",
            "yolov8n-face.pt.1   100%[===================>]   5.96M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-06-24 07:33:26 (60.7 MB/s) - ‘yolov8n-face.pt.1’ saved [6250099/6250099]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import json\n",
        "import time\n",
        "import sqlite3\n",
        "import logging\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from ultralytics import YOLO\n",
        "from facenet_pytorch import InceptionResnetV1\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "from sklearn.cluster import DBSCAN\n",
        "from typing import List, Tuple, Dict, Optional\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, clear_output\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "B-gxqs0p2S00"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USE_RTSP = False  # Set to True for RTSP stream, False for video file\n",
        "\n",
        "# RTSP configuration\n",
        "RTSP_URL = \"rtsp://username:password@ip_address:port/stream\"\n",
        "RTSP_OPTIONS = {\n",
        "    \"buffer_size\": 1,\n",
        "    \"fps\": 15,\n",
        "    \"frame_size\": (1280, 720)\n",
        "}\n",
        "\n",
        "# Video file configuration\n",
        "VIDEO_FILE = \"https://github.com/intel-iot-devkit/sample-videos/raw/master/face-demographics-walking.mp4\"\n",
        "VIDEO_OPTIONS = {\n",
        "    \"buffer_size\": 10,\n",
        "    \"fps\": 30\n",
        "}\n",
        "\n",
        "# Common configuration\n",
        "config = {\n",
        "    \"detection_interval\": 1 if USE_RTSP else 1,\n",
        "    \"min_confidence\": 0.25,\n",
        "    \"recognition_threshold\": 0.55,\n",
        "    \"max_age\": 30,\n",
        "    \"n_init\": 3,\n",
        "    \"log_dir\": \"logs\",\n",
        "    \"db_path\": \"faces.db\",\n",
        "    \"display_frames\": 5 if USE_RTSP else 10,\n",
        "    \"cluster_eps\": 0.5,\n",
        "    \"min_samples\": 2,\n",
        "    \"min_face_size\": 20,\n",
        "    \"source_type\": \"rtsp\" if USE_RTSP else \"video\",\n",
        "    \"source\": RTSP_URL if USE_RTSP else VIDEO_FILE,\n",
        "    \"source_options\": RTSP_OPTIONS if USE_RTSP else VIDEO_OPTIONS\n",
        "}"
      ],
      "metadata": {
        "id": "HGHPX-Ng2VGs"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_logging(log_dir):\n",
        "    os.makedirs(log_dir, exist_ok=True)\n",
        "    logging.basicConfig(\n",
        "        filename=os.path.join(log_dir, 'events.log'),\n",
        "        level=logging.INFO,\n",
        "        format='%(asctime)s - %(levelname)s - %(message)s'\n",
        "    )\n",
        "    console = logging.StreamHandler()\n",
        "    console.setLevel(logging.INFO)\n",
        "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "    console.setFormatter(formatter)\n",
        "    logging.getLogger('').addHandler(console)\n",
        "    return logging.getLogger()\n",
        "\n",
        "logger = setup_logging(config['log_dir'])\n",
        "logger.info(f\"System initialized for {config['source_type'].upper()} source\")"
      ],
      "metadata": {
        "id": "ntbaYlcZ2Xp-"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FaceDetector:\n",
        "    def __init__(self, min_confidence=0.25):\n",
        "        logger.info(\"Loading YOLOv8-face model...\")\n",
        "        self.model = YOLO('yolov8n-face.pt')\n",
        "        self.min_confidence = min_confidence\n",
        "        logger.info(\"YOLOv8-face model loaded successfully\")\n",
        "\n",
        "    def detect(self, frame: np.ndarray) -> Tuple[List, List]:\n",
        "        try:\n",
        "            results = self.model(frame, verbose=False)[0]\n",
        "            bboxes = []\n",
        "            confidences = []\n",
        "\n",
        "            for box in results.boxes:\n",
        "                conf = box.conf.item()\n",
        "                cls = int(box.cls.item())\n",
        "                if cls == 0 and conf > self.min_confidence:\n",
        "                    x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
        "                    bboxes.append([x1, y1, x2 - x1, y2 - y1])\n",
        "                    confidences.append(conf)\n",
        "\n",
        "            logger.debug(f\"Detected {len(bboxes)} faces\")\n",
        "            return bboxes, confidences\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Detection error: {str(e)}\")\n",
        "            return [], []\n",
        "\n",
        "    def crop_face(self, frame: np.ndarray, face_bbox: List[int]) -> Optional[np.ndarray]:\n",
        "        try:\n",
        "            x, y, w, h = face_bbox\n",
        "            expand = 0.1\n",
        "            x1 = max(0, int(x - w * expand))\n",
        "            y1 = max(0, int(y - h * expand))\n",
        "            x2 = min(frame.shape[1], int(x + w * (1 + expand)))\n",
        "            y2 = min(frame.shape[0], int(y + h * (1 + expand)))\n",
        "            face_img = frame[y1:y2, x1:x2]\n",
        "            if face_img.size == 0 or face_img.shape[0] < config['min_face_size'] or face_img.shape[1] < config['min_face_size']:\n",
        "                return None\n",
        "            return face_img\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Face cropping error: {str(e)}\")\n",
        "            return None"
      ],
      "metadata": {
        "id": "b5ccpjO02aOx"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FaceRecognizer:\n",
        "    def __init__(self, recognition_threshold=0.55):\n",
        "        self.threshold = recognition_threshold\n",
        "        self.known_faces = {}\n",
        "        self.next_id = 1\n",
        "        logger.info(\"Loading FaceNet model...\")\n",
        "        self.resnet = InceptionResnetV1(pretrained='vggface2').eval()\n",
        "        logger.info(\"FaceNet model loaded successfully\")\n",
        "\n",
        "    def get_embedding(self, face_img: np.ndarray) -> np.ndarray:\n",
        "        try:\n",
        "            face_img = cv2.resize(face_img, (160, 160))\n",
        "            face_img = face_img.astype(np.float32)\n",
        "            face_img = (face_img - 127.5) / 128.0\n",
        "            face_img = np.transpose(face_img, (2, 0, 1))\n",
        "            face_img = torch.tensor(face_img).unsqueeze(0)\n",
        "            with torch.no_grad():\n",
        "                embedding = self.resnet(face_img)\n",
        "            return embedding.numpy().flatten()\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Embedding generation error: {str(e)}\")\n",
        "            return np.array([])\n",
        "\n",
        "    def recognize_face(self, embedding: np.ndarray) -> Optional[int]:\n",
        "        if not self.known_faces or embedding.size == 0:\n",
        "            return None\n",
        "        best_match = None\n",
        "        min_distance = float('inf')\n",
        "        for face_id, known_embedding in self.known_faces.items():\n",
        "            distance = np.linalg.norm(embedding - known_embedding)\n",
        "            if distance < min_distance and distance < self.threshold:\n",
        "                min_distance = distance\n",
        "                best_match = face_id\n",
        "        return best_match\n",
        "\n",
        "    def register_face(self, embedding: np.ndarray) -> int:\n",
        "        if embedding.size == 0:\n",
        "            return -1\n",
        "        face_id = self.next_id\n",
        "        self.next_id += 1\n",
        "        self.known_faces[face_id] = embedding\n",
        "        logger.info(f\"Registered new face: ID {face_id}\")\n",
        "        return face_id"
      ],
      "metadata": {
        "id": "oEFD1h6n2dVx"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FaceDB:\n",
        "    def __init__(self, db_path: str):\n",
        "        self.db_path = db_path\n",
        "        self.conn = sqlite3.connect(db_path)\n",
        "        self.create_tables()\n",
        "        logger.info(f\"Database connection established: {db_path}\")\n",
        "\n",
        "    def create_tables(self):\n",
        "        cursor = self.conn.cursor()\n",
        "        cursor.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS events (\n",
        "                event_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                face_id INTEGER NOT NULL,\n",
        "                true_id INTEGER,\n",
        "                event_type TEXT NOT NULL CHECK(event_type IN ('entry', 'exit')),\n",
        "                timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
        "                image_path TEXT NOT NULL\n",
        "            )\n",
        "        ''')\n",
        "        self.conn.commit()\n",
        "        logger.info(\"Database tables created\")\n",
        "\n",
        "    def add_event(self, face_id: int, event_type: str, image_path: str):\n",
        "        try:\n",
        "            cursor = self.conn.cursor()\n",
        "            cursor.execute('''\n",
        "                INSERT INTO events (face_id, event_type, image_path)\n",
        "                VALUES (?, ?, ?)\n",
        "            ''', (face_id, event_type, image_path))\n",
        "            self.conn.commit()\n",
        "            logger.info(f\"Logged {event_type} event for face ID {face_id}\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error adding event to database: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def update_true_ids(self, face_id_mapping: Dict[int, int]):\n",
        "        try:\n",
        "            cursor = self.conn.cursor()\n",
        "            for face_id, true_id in face_id_mapping.items():\n",
        "                cursor.execute('''\n",
        "                    UPDATE events\n",
        "                    SET true_id = ?\n",
        "                    WHERE face_id = ?\n",
        "                ''', (true_id, face_id))\n",
        "            self.conn.commit()\n",
        "            logger.info(f\"Updated {len(face_id_mapping)} true IDs in database\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error updating true IDs: {str(e)}\")\n",
        "\n",
        "    def get_unique_count(self) -> int:\n",
        "        try:\n",
        "            cursor = self.conn.cursor()\n",
        "            cursor.execute('SELECT COUNT(DISTINCT true_id) FROM events WHERE event_type=\"entry\" AND true_id IS NOT NULL')\n",
        "            count = cursor.fetchone()[0] or 0\n",
        "            logger.info(f\"Database unique count: {count}\")\n",
        "            return count\n",
        "        except:\n",
        "            return 0\n",
        "\n",
        "    def get_event_count(self) -> int:\n",
        "        try:\n",
        "            cursor = self.conn.cursor()\n",
        "            cursor.execute('SELECT COUNT(*) FROM events')\n",
        "            return cursor.fetchone()[0]\n",
        "        except:\n",
        "            return 0\n",
        "\n",
        "    def close(self):\n",
        "        self.conn.close()\n",
        "        logger.info(\"Database connection closed\")"
      ],
      "metadata": {
        "id": "iO7UM2rN2gDx"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EventLogger:\n",
        "    def __init__(self, log_dir: str, db: FaceDB):\n",
        "        self.log_dir = log_dir\n",
        "        self.db = db\n",
        "        logger.info(\"Event logger initialized\")\n",
        "\n",
        "    def log_event(self, face_id: int, event_type: str, face_img: np.ndarray) -> bool:\n",
        "        try:\n",
        "            date_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "            event_dir = os.path.join(\n",
        "                self.log_dir,\n",
        "                \"entries\" if event_type == \"entry\" else \"exits\",\n",
        "                date_str\n",
        "            )\n",
        "            os.makedirs(event_dir, exist_ok=True)\n",
        "            timestamp_str = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "            img_path = os.path.join(event_dir, f\"{face_id}_{timestamp_str}.jpg\")\n",
        "            cv2.imwrite(img_path, face_img)\n",
        "            logger.debug(f\"Saved face image: {img_path}\")\n",
        "            if self.db.add_event(face_id, event_type, img_path):\n",
        "                logger.info(f\"{event_type.upper()} - Face ID: {face_id} - Image: {img_path}\")\n",
        "                return True\n",
        "            return False\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error logging event: {str(e)}\")\n",
        "            return False"
      ],
      "metadata": {
        "id": "H47tnMOd2iOi"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FaceClusterer:\n",
        "    def __init__(self, db_path: str, recognizer: FaceRecognizer):\n",
        "        self.db_path = db_path\n",
        "        self.recognizer = recognizer\n",
        "        logger.info(\"Face clusterer initialized\")\n",
        "\n",
        "    def cluster_faces(self, eps=0.5, min_samples=2):\n",
        "        try:\n",
        "            conn = sqlite3.connect(self.db_path)\n",
        "            cursor = conn.cursor()\n",
        "            cursor.execute(\"SELECT face_id, image_path FROM events\")\n",
        "            face_records = cursor.fetchall()\n",
        "            if not face_records:\n",
        "                logger.warning(\"No face records found for clustering\")\n",
        "                return {}\n",
        "            logger.info(f\"Found {len(face_records)} face records for clustering\")\n",
        "            embeddings = []\n",
        "            face_ids = []\n",
        "            valid_paths = []\n",
        "            for i, (face_id, image_path) in enumerate(face_records):\n",
        "                if os.path.exists(image_path):\n",
        "                    try:\n",
        "                        img = cv2.imread(image_path)\n",
        "                        if img is None or img.size == 0:\n",
        "                            continue\n",
        "                        embedding = self.recognizer.get_embedding(img)\n",
        "                        if embedding.size > 0:\n",
        "                            embeddings.append(embedding)\n",
        "                            face_ids.append(face_id)\n",
        "                            valid_paths.append(image_path)\n",
        "                    except:\n",
        "                        continue\n",
        "            if not embeddings:\n",
        "                logger.error(\"No valid embeddings found for clustering\")\n",
        "                return {}\n",
        "            logger.info(f\"Clustering {len(embeddings)} face embeddings...\")\n",
        "            clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(embeddings)\n",
        "            labels = clustering.labels_\n",
        "            true_id_mapping = {}\n",
        "            for face_id, label in zip(face_ids, labels):\n",
        "                if label != -1:\n",
        "                    true_id_mapping[face_id] = label\n",
        "            self.update_database(conn, true_id_mapping)\n",
        "            logger.info(f\"Clustering completed: {len(true_id_mapping)} faces mapped to {len(set(true_id_mapping.values()))} identities\")\n",
        "            return true_id_mapping\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Clustering error: {str(e)}\", exc_info=True)\n",
        "            return {}\n",
        "        finally:\n",
        "            conn.close()\n",
        "\n",
        "    def update_database(self, conn, true_id_mapping):\n",
        "        cursor = conn.cursor()\n",
        "        for face_id, true_id in true_id_mapping.items():\n",
        "            cursor.execute('''\n",
        "                UPDATE events\n",
        "                SET true_id = ?\n",
        "                WHERE face_id = ?\n",
        "            ''', (true_id, face_id))\n",
        "        conn.commit()"
      ],
      "metadata": {
        "id": "CDvRzPGX2k3h"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VideoSource:\n",
        "    def __init__(self, source, options):\n",
        "        self.source = source\n",
        "        self.options = options\n",
        "        self.cap = None\n",
        "        self.last_frame_time = 0\n",
        "        self.frame_interval = 1 / options.get('fps', 30)\n",
        "\n",
        "    def open(self):\n",
        "        logger.info(f\"Opening video source: {self.source}\")\n",
        "        if \"rtsp\" in self.source.lower():\n",
        "            os.environ[\"OPENCV_FFMPEG_CAPTURE_OPTIONS\"] = \"rtsp_transport;tcp\"\n",
        "            self.cap = cv2.VideoCapture(self.source, cv2.CAP_FFMPEG)\n",
        "            self.cap.set(cv2.CAP_PROP_BUFFERSIZE, self.options.get('buffer_size', 1))\n",
        "            self.cap.set(cv2.CAP_PROP_FPS, self.options.get('fps', 15))\n",
        "            frame_size = self.options.get('frame_size')\n",
        "            if frame_size:\n",
        "                self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, frame_size[0])\n",
        "                self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, frame_size[1])\n",
        "        else:\n",
        "            self.cap = cv2.VideoCapture(self.source)\n",
        "            self.cap.set(cv2.CAP_PROP_BUFFERSIZE, self.options.get('buffer_size', 10))\n",
        "        if not self.cap.isOpened():\n",
        "            logger.error(f\"Failed to open video source: {self.source}\")\n",
        "            return False\n",
        "        width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        fps = self.cap.get(cv2.CAP_PROP_FPS)\n",
        "        total_frames = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        logger.info(f\"Video: {width}x{height} @ {fps:.2f} FPS, {total_frames if total_frames > 0 else 'unlimited'} frames\")\n",
        "        return True\n",
        "\n",
        "    def read(self):\n",
        "        if \"rtsp\" in self.source.lower():\n",
        "            current_time = time.time()\n",
        "            elapsed = current_time - self.last_frame_time\n",
        "            if elapsed < self.frame_interval:\n",
        "                time.sleep(self.frame_interval - elapsed)\n",
        "            self.last_frame_time = time.time()\n",
        "        ret, frame = self.cap.read()\n",
        "        return ret, frame\n",
        "\n",
        "    def release(self):\n",
        "        if self.cap and self.cap.isOpened():\n",
        "            self.cap.release()\n",
        "            logger.info(\"Video source released\")"
      ],
      "metadata": {
        "id": "Q86VszNI2m18"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FaceTrackerApp:\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        logger.info(\"Initializing application components...\")\n",
        "        self.detector = FaceDetector(min_confidence=config['min_confidence'])\n",
        "        self.recognizer = FaceRecognizer(recognition_threshold=config['recognition_threshold'])\n",
        "        self.db = FaceDB(config['db_path'])\n",
        "        self.logger = EventLogger(config['log_dir'], self.db)\n",
        "        self.tracker = DeepSort(max_age=config['max_age'], n_init=config['n_init'])\n",
        "        self.video_source = VideoSource(config['source'], config['source_options'])\n",
        "        self.frame_count = 0\n",
        "        self.unique_visitors = 0\n",
        "        self.active_faces = {}\n",
        "        logger.info(\"Application initialized\")\n",
        "\n",
        "    def process_frame(self, frame: np.ndarray):\n",
        "        self.frame_count += 1\n",
        "        run_detection = (self.frame_count % self.config['detection_interval'] == 0)\n",
        "        detections = []\n",
        "        if run_detection:\n",
        "            bboxes, confs = self.detector.detect(frame)\n",
        "            detections = [(bbox, conf) for bbox, conf in zip(bboxes, confs)]\n",
        "        detections_for_tracker = []\n",
        "        for bbox, conf in detections:\n",
        "            x, y, w, h = bbox\n",
        "            detections_for_tracker.append(([x, y, w, h], conf))\n",
        "        tracks = self.tracker.update_tracks(detections_for_tracker, frame=frame)\n",
        "        logger.debug(f\"Tracking {len(tracks)} objects\")\n",
        "        for track in tracks:\n",
        "            if not track.is_confirmed() or track.time_since_update != 0:\n",
        "                continue\n",
        "            track_id = track.track_id\n",
        "            bbox = track.to_ltrb()\n",
        "            x1, y1, x2, y2 = map(int, bbox)\n",
        "            w, h = x2 - x1, y2 - y1\n",
        "            face_bbox = [x1, y1, w, h]\n",
        "            face_img = self.detector.crop_face(frame, face_bbox)\n",
        "            if face_img is None:\n",
        "                continue\n",
        "            if track_id not in self.active_faces:\n",
        "                try:\n",
        "                    logger.debug(f\"Processing new track: {track_id}\")\n",
        "                    embedding = self.recognizer.get_embedding(face_img)\n",
        "                    if embedding.size == 0:\n",
        "                        continue\n",
        "                    face_id = self.recognizer.recognize_face(embedding)\n",
        "                    if face_id is None:\n",
        "                        face_id = self.recognizer.register_face(embedding)\n",
        "                        if face_id > 0:\n",
        "                            logger.info(f\"Registering new face ID: {face_id}\")\n",
        "                            self.logger.log_event(face_id, \"entry\", face_img)\n",
        "                    if face_id > 0:\n",
        "                        self.active_faces[track_id] = {\n",
        "                            'face_id': face_id,\n",
        "                            'last_face': face_img,\n",
        "                            'has_logged_exit': False\n",
        "                        }\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"Face processing error: {str(e)}\")\n",
        "        active_track_ids = {t.track_id for t in tracks if t.is_confirmed()}\n",
        "        exited_tracks = set(self.active_faces.keys()) - active_track_ids\n",
        "        for track_id in exited_tracks:\n",
        "            if not self.active_faces[track_id]['has_logged_exit']:\n",
        "                face_id = self.active_faces[track_id]['face_id']\n",
        "                if face_id > 0:\n",
        "                    logger.info(f\"Logging exit for face ID: {face_id}\")\n",
        "                    self.logger.log_event(face_id, \"exit\", self.active_faces[track_id]['last_face'])\n",
        "                self.active_faces[track_id]['has_logged_exit'] = True\n",
        "                del self.active_faces[track_id]\n",
        "        return self.visualize_frame(frame, tracks)\n",
        "\n",
        "    def visualize_frame(self, frame, tracks):\n",
        "        display_frame = frame.copy()\n",
        "        for track in tracks:\n",
        "            if not track.is_confirmed():\n",
        "                continue\n",
        "            track_id = track.track_id\n",
        "            bbox = track.to_ltrb()\n",
        "            x1, y1, x2, y2 = map(int, bbox)\n",
        "            if track_id in self.active_faces:\n",
        "                face_id = self.active_faces[track_id]['face_id']\n",
        "                color = (0, 255, 0)\n",
        "                cv2.rectangle(display_frame, (x1, y1), (x2, y2), color, 2)\n",
        "                cv2.putText(display_frame, f\"ID: {face_id}\", (x1, y1-10),\n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "            else:\n",
        "                cv2.rectangle(display_frame, (x1, y1), (x2, y2), (255, 0, 0), 1)\n",
        "                cv2.putText(display_frame, f\"TRK: {track_id}\", (x1, y1-10),\n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
        "        source_info = f\"{self.config['source_type'].upper()}: {os.path.basename(self.config['source'])}\"\n",
        "        cv2.putText(display_frame, source_info,\n",
        "                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
        "        cv2.putText(display_frame, f\"Unique Visitors: {self.unique_visitors}\",\n",
        "                   (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "        cv2.putText(display_frame, f\"Frame: {self.frame_count}\",\n",
        "                   (10, 110), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "        time_str = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        cv2.putText(display_frame, time_str,\n",
        "                   (display_frame.shape[1] - 300, 30),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
        "        return display_frame\n",
        "\n",
        "    def run(self, display=True):\n",
        "        try:\n",
        "            if not self.video_source.open():\n",
        "                return\n",
        "            start_time = time.time()\n",
        "            frame_count = 0\n",
        "            while True:\n",
        "                ret, frame = self.video_source.read()\n",
        "                if not ret:\n",
        "                    logger.info(\"End of video stream\")\n",
        "                    break\n",
        "                display_frame = self.process_frame(frame)\n",
        "                frame_count += 1\n",
        "                if display and frame_count % config['display_frames'] == 0:\n",
        "                    display_frame_rgb = cv2.cvtColor(display_frame, cv2.COLOR_BGR2RGB)\n",
        "                    plt.figure(figsize=(12, 8))\n",
        "                    plt.imshow(display_frame_rgb)\n",
        "                    plt.axis('off')\n",
        "                    plt.title(f\"Frame {frame_count} | Visitors: {self.unique_visitors}\")\n",
        "                    plt.show()\n",
        "                    clear_output(wait=True)\n",
        "                if frame_count % 100 == 0:\n",
        "                    elapsed = time.time() - start_time\n",
        "                    fps = frame_count / elapsed\n",
        "                    logger.info(f\"Processed {frame_count} frames @ {fps:.1f} FPS\")\n",
        "                    logger.info(f\"Active tracks: {len(self.active_faces)}\")\n",
        "                    logger.info(f\"Registered faces: {len(self.recognizer.known_faces)}\")\n",
        "                    logger.info(f\"Database events: {self.db.get_event_count()}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Processing error: {str(e)}\", exc_info=True)\n",
        "        finally:\n",
        "            self.video_source.release()\n",
        "            logger.info(\"Starting face clustering...\")\n",
        "            clusterer = FaceClusterer(config['db_path'], self.recognizer)\n",
        "            clusterer.cluster_faces(\n",
        "                eps=config['cluster_eps'],\n",
        "                min_samples=config['min_samples']\n",
        "            )\n",
        "            self.unique_visitors = self.db.get_unique_count()\n",
        "            self.db.close()\n",
        "            logger.info(f\"Unique visitors after clustering: {self.unique_visitors}\")\n",
        "            logger.info(\"Processing completed\")\n",
        "            self.save_sample_outputs()\n",
        "\n",
        "    def save_sample_outputs(self):\n",
        "        logger.info(\"Saving sample outputs...\")\n",
        "        with open('config.json', 'w') as f:\n",
        "            json.dump(config, f, indent=2)\n",
        "        conn = sqlite3.connect(config['db_path'])\n",
        "        try:\n",
        "            events_df = pd.read_sql_query(\"SELECT * FROM events\", conn)\n",
        "            events_df.to_csv('sample_events.csv', index=False)\n",
        "            if 'true_id' in events_df.columns:\n",
        "                unique_df = events_df[events_df['event_type'] == 'entry']\n",
        "                unique_df = unique_df.drop_duplicates('true_id')\n",
        "                unique_df.to_csv('unique_visitors.csv', index=False)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Could not export tables: {str(e)}\")\n",
        "        !cp logs/events.log sample_events.log 2>/dev/null || echo \"No log file\"\n",
        "        !cp logs/entries/*/*.jpg sample_images/ 2>/dev/null || true\n",
        "        !cp logs/exits/*/*.jpg sample_images/ 2>/dev/null || true\n",
        "        try:\n",
        "            cap = cv2.VideoCapture(config['source'])\n",
        "            ret, frame = cap.read()\n",
        "            if ret:\n",
        "                cv2.imwrite('sample_frame.jpg', frame)\n",
        "            cap.release()\n",
        "        except:\n",
        "            pass\n",
        "        conn.close()\n",
        "        logger.info(\"Sample outputs saved\")"
      ],
      "metadata": {
        "id": "a7Cw_Ka02pPD"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger.info(\"Starting application...\")\n",
        "app = FaceTrackerApp(config)\n",
        "app.run(display=True)\n",
        "\n",
        "!zip -r submission.zip logs/ config.json sample_*.* sample_images/ 2>/dev/null\n",
        "\n",
        "print(\"\\nSystem Output Summary:\")\n",
        "print(f\"Source Type: {config['source_type'].upper()}\")\n",
        "print(f\"Unique Visitors: {app.unique_visitors}\")\n",
        "\n",
        "try:\n",
        "    conn = sqlite3.connect(config['db_path'])\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT COUNT(*) FROM events\")\n",
        "    total_events = cursor.fetchone()[0]\n",
        "    cursor.execute(\"SELECT COUNT(DISTINCT face_id) FROM events\")\n",
        "    unique_faces = cursor.fetchone()[0]\n",
        "    cursor.execute(\"SELECT COUNT(DISTINCT true_id) FROM events WHERE event_type='entry' AND true_id IS NOT NULL\")\n",
        "    unique_visitors = cursor.fetchone()[0]\n",
        "    print(f\"\\nDatabase Statistics:\")\n",
        "    print(f\"Total events: {total_events}\")\n",
        "    print(f\"Unique face IDs: {unique_faces}\")\n",
        "    print(f\"Unique visitors (after clustering): {unique_visitors}\")\n",
        "    if total_events > 0:\n",
        "        print(\"\\nFirst 5 events:\")\n",
        "        cursor.execute(\"SELECT * FROM events LIMIT 5\")\n",
        "        for row in cursor.fetchall():\n",
        "            print(row)\n",
        "    conn.close()\n",
        "except Exception as e:\n",
        "    print(f\"\\nError accessing database: {str(e)}\")\n",
        "\n",
        "print(\"\\nSample Images in logs directory:\")\n",
        "!find logs -name \"*.jpg\" | head -n 5 2>/dev/null || echo \"No images found\"\n",
        "\n",
        "try:\n",
        "    sample_face = !find logs -name \"*.jpg\" | head -n 1\n",
        "    if sample_face:\n",
        "        print(\"\\nSample Face Image:\")\n",
        "        display(Image(filename=sample_face[0]))\n",
        "except:\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "U4w4egmF2sWd",
        "outputId": "24be85d5-ab91-4795-9f2d-24a44a353127"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No log file\n",
            "updating: logs/ (stored 0%)\n",
            "updating: logs/entries/ (stored 0%)\n",
            "updating: logs/entries/2025-06-24/ (stored 0%)\n",
            "updating: logs/entries/2025-06-24/5_20250624073640.jpg (deflated 25%)\n",
            "updating: logs/entries/2025-06-24/3_20250624073535.jpg (deflated 27%)\n",
            "updating: logs/entries/2025-06-24/7_20250624073738.jpg (deflated 22%)\n",
            "updating: logs/entries/2025-06-24/6_20250624073644.jpg (deflated 20%)\n",
            "updating: logs/entries/2025-06-24/2_20250624073507.jpg (deflated 3%)\n",
            "updating: logs/entries/2025-06-24/4_20250624073543.jpg (deflated 22%)\n",
            "updating: logs/entries/2025-06-24/1_20250624073438.jpg (deflated 25%)\n",
            "updating: logs/exits/ (stored 0%)\n",
            "updating: logs/exits/2025-06-24/ (stored 0%)\n",
            "updating: logs/exits/2025-06-24/7_20250624073804.jpg (deflated 22%)\n",
            "updating: logs/exits/2025-06-24/6_20250624073714.jpg (deflated 20%)\n",
            "updating: logs/exits/2025-06-24/5_20250624073715.jpg (deflated 25%)\n",
            "updating: logs/exits/2025-06-24/3_20250624073711.jpg (deflated 25%)\n",
            "updating: logs/exits/2025-06-24/1_20250624073516.jpg (deflated 25%)\n",
            "updating: logs/exits/2025-06-24/2_20250624073517.jpg (deflated 3%)\n",
            "updating: logs/exits/2025-06-24/3_20250624073612.jpg (deflated 27%)\n",
            "updating: logs/exits/2025-06-24/4_20250624073612.jpg (deflated 22%)\n",
            "updating: config.json (deflated 42%)\n",
            "updating: sample_events.csv (deflated 86%)\n",
            "updating: sample_frame.jpg (deflated 1%)\n",
            "updating: sample_images/ (stored 0%)\n",
            "updating: sample_images/7_20250624073804.jpg (deflated 22%)\n",
            "updating: sample_images/5_20250624073640.jpg (deflated 25%)\n",
            "updating: sample_images/3_20250624073535.jpg (deflated 27%)\n",
            "updating: sample_images/7_20250624073738.jpg (deflated 22%)\n",
            "updating: sample_images/6_20250624073714.jpg (deflated 20%)\n",
            "updating: sample_images/5_20250624073715.jpg (deflated 25%)\n",
            "updating: sample_images/6_20250624073644.jpg (deflated 20%)\n",
            "updating: sample_images/3_20250624073711.jpg (deflated 25%)\n",
            "updating: sample_images/2_20250624073507.jpg (deflated 3%)\n",
            "updating: sample_images/1_20250624073516.jpg (deflated 25%)\n",
            "updating: sample_images/2_20250624073517.jpg (deflated 3%)\n",
            "updating: sample_images/4_20250624073543.jpg (deflated 22%)\n",
            "updating: sample_images/1_20250624073438.jpg (deflated 25%)\n",
            "updating: sample_images/3_20250624073612.jpg (deflated 27%)\n",
            "updating: sample_images/4_20250624073612.jpg (deflated 22%)\n",
            "updating: logs/entries/2025-06-24/4_20250624081412.jpg (deflated 22%)\n",
            "updating: logs/entries/2025-06-24/5_20250624081513.jpg (deflated 25%)\n",
            "updating: logs/entries/2025-06-24/2_20250624081336.jpg (deflated 3%)\n",
            "updating: logs/entries/2025-06-24/3_20250624081404.jpg (deflated 27%)\n",
            "updating: logs/entries/2025-06-24/1_20250624081309.jpg (deflated 25%)\n",
            "updating: logs/entries/2025-06-24/7_20250624081611.jpg (deflated 22%)\n",
            "updating: logs/entries/2025-06-24/6_20250624081517.jpg (deflated 20%)\n",
            "updating: logs/exits/2025-06-24/5_20250624081549.jpg (deflated 25%)\n",
            "updating: logs/exits/2025-06-24/2_20250624081345.jpg (deflated 3%)\n",
            "updating: logs/exits/2025-06-24/3_20250624081443.jpg (deflated 27%)\n",
            "updating: logs/exits/2025-06-24/4_20250624081443.jpg (deflated 22%)\n",
            "updating: logs/exits/2025-06-24/1_20250624081344.jpg (deflated 25%)\n",
            "updating: logs/exits/2025-06-24/7_20250624081639.jpg (deflated 22%)\n",
            "updating: logs/exits/2025-06-24/6_20250624081548.jpg (deflated 20%)\n",
            "updating: logs/exits/2025-06-24/3_20250624081544.jpg (deflated 25%)\n",
            "updating: sample_images/4_20250624081412.jpg (deflated 22%)\n",
            "updating: sample_images/5_20250624081549.jpg (deflated 25%)\n",
            "updating: sample_images/2_20250624081345.jpg (deflated 3%)\n",
            "updating: sample_images/5_20250624081513.jpg (deflated 25%)\n",
            "updating: sample_images/2_20250624081336.jpg (deflated 3%)\n",
            "updating: sample_images/3_20250624081404.jpg (deflated 27%)\n",
            "updating: sample_images/3_20250624081443.jpg (deflated 27%)\n",
            "updating: sample_images/4_20250624081443.jpg (deflated 22%)\n",
            "updating: sample_images/1_20250624081309.jpg (deflated 25%)\n",
            "updating: sample_images/7_20250624081611.jpg (deflated 22%)\n",
            "updating: sample_images/1_20250624081344.jpg (deflated 25%)\n",
            "updating: sample_images/6_20250624081517.jpg (deflated 20%)\n",
            "updating: sample_images/7_20250624081639.jpg (deflated 22%)\n",
            "updating: sample_images/6_20250624081548.jpg (deflated 20%)\n",
            "updating: sample_images/3_20250624081544.jpg (deflated 25%)\n",
            "  adding: logs/entries/2025-06-24/3_20250624084448.jpg (deflated 27%)\n",
            "  adding: logs/entries/2025-06-24/4_20250624084455.jpg (deflated 22%)\n",
            "  adding: logs/entries/2025-06-24/1_20250624084352.jpg (deflated 25%)\n",
            "  adding: logs/entries/2025-06-24/2_20250624084421.jpg (deflated 3%)\n",
            "  adding: logs/entries/2025-06-24/6_20250624084557.jpg (deflated 20%)\n",
            "  adding: logs/entries/2025-06-24/5_20250624084552.jpg (deflated 25%)\n",
            "  adding: logs/entries/2025-06-24/7_20250624084650.jpg (deflated 22%)\n",
            "  adding: logs/exits/2025-06-24/3_20250624084624.jpg (deflated 25%)\n",
            "  adding: logs/exits/2025-06-24/4_20250624084525.jpg (deflated 22%)\n",
            "  adding: logs/exits/2025-06-24/2_20250624084428.jpg (deflated 3%)\n",
            "  adding: logs/exits/2025-06-24/1_20250624084428.jpg (deflated 25%)\n",
            "  adding: logs/exits/2025-06-24/5_20250624084628.jpg (deflated 25%)\n",
            "  adding: logs/exits/2025-06-24/3_20250624084525.jpg (deflated 27%)\n",
            "  adding: logs/exits/2025-06-24/7_20250624084717.jpg (deflated 22%)\n",
            "  adding: logs/exits/2025-06-24/6_20250624084628.jpg (deflated 20%)\n",
            "  adding: sample_images/3_20250624084624.jpg (deflated 25%)\n",
            "  adding: sample_images/4_20250624084525.jpg (deflated 22%)\n",
            "  adding: sample_images/2_20250624084428.jpg (deflated 3%)\n",
            "  adding: sample_images/3_20250624084448.jpg (deflated 27%)\n",
            "  adding: sample_images/1_20250624084428.jpg (deflated 25%)\n",
            "  adding: sample_images/5_20250624084628.jpg (deflated 25%)\n",
            "  adding: sample_images/3_20250624084525.jpg (deflated 27%)\n",
            "  adding: sample_images/4_20250624084455.jpg (deflated 22%)\n",
            "  adding: sample_images/7_20250624084717.jpg (deflated 22%)\n",
            "  adding: sample_images/6_20250624084628.jpg (deflated 20%)\n",
            "  adding: sample_images/1_20250624084352.jpg (deflated 25%)\n",
            "  adding: sample_images/2_20250624084421.jpg (deflated 3%)\n",
            "  adding: sample_images/6_20250624084557.jpg (deflated 20%)\n",
            "  adding: sample_images/5_20250624084552.jpg (deflated 25%)\n",
            "  adding: sample_images/7_20250624084650.jpg (deflated 22%)\n",
            "\n",
            "System Output Summary:\n",
            "Source Type: VIDEO\n",
            "Unique Visitors: 7\n",
            "\n",
            "Database Statistics:\n",
            "Total events: 45\n",
            "Unique face IDs: 7\n",
            "Unique visitors (after clustering): 7\n",
            "\n",
            "First 5 events:\n",
            "(1, 1, b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00', 'entry', '2025-06-24 07:34:38', 'logs/entries/2025-06-24/1_20250624073438.jpg')\n",
            "(2, 2, b'\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00', 'entry', '2025-06-24 07:35:07', 'logs/entries/2025-06-24/2_20250624073507.jpg')\n",
            "(3, 1, b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00', 'exit', '2025-06-24 07:35:16', 'logs/exits/2025-06-24/1_20250624073516.jpg')\n",
            "(4, 2, b'\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00', 'exit', '2025-06-24 07:35:17', 'logs/exits/2025-06-24/2_20250624073517.jpg')\n",
            "(5, 3, b'\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00', 'entry', '2025-06-24 07:35:35', 'logs/entries/2025-06-24/3_20250624073535.jpg')\n",
            "\n",
            "Sample Images in logs directory:\n",
            "logs/entries/2025-06-24/4_20250624081412.jpg\n",
            "logs/entries/2025-06-24/5_20250624081513.jpg\n",
            "logs/entries/2025-06-24/2_20250624081336.jpg\n",
            "logs/entries/2025-06-24/5_20250624073640.jpg\n",
            "logs/entries/2025-06-24/3_20250624084448.jpg\n",
            "\n",
            "Sample Face Image:\n"
          ]
        }
      ]
    }
  ]
}